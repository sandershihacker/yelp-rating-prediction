{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Restaurant Rating Prediction\n",
    "\n",
    "## Project Description\n",
    "The project goal is to predict restaurant overall ratings on yelp\n",
    "in New York City, using multiple features of restaurants that we will\n",
    "extract using the yelp API. Our motivation is to help determine how\n",
    "successful a new restaurant business might be, given certain known\n",
    "characteristics of it.\n",
    "\n",
    "We will use the Yelp API, with the help of pandas, to acquire raw data\n",
    "from restaurants. Then we will extract reasonable features such as\n",
    "location, open hours, whether it takes reservations, whether it has\n",
    "delivery service, whether there is parking space, and whether it\n",
    "provides free wifi etc., from the parsed data, and combine with the\n",
    "overall ratings, which is a numerical value ranging from 0 to 5, as\n",
    "labels.\n",
    "\n",
    "We will model the rating distribution over the different features that\n",
    "we extract and create, and analyse how much each feature shifts our\n",
    "distribution. Using our results from this we will select good features\n",
    "to train on machine learning models.\n",
    "\n",
    "Using the labeled features that we construct, we will train different\n",
    "machine learning models like linear regression, nonlinear regression,\n",
    "logistic regression as well as neural networks, then make some\n",
    "predictions, and compare the accuracy obtained from them.\n",
    "\n",
    "## Team Members\n",
    "Jun Hee Kim, Nikhil Rangarajan, Sander Shi\n",
    "\n",
    "## Procedure\n",
    "* [Data Gathering from API](#step-1)\n",
    "* [Feature Extraction with Parsing](#step-2)\n",
    "* [Feature Analysis and Variable Selection](#step-3)\n",
    "* [Setup of Models](#step-4)\n",
    "* [Cross Validation](#step-5)\n",
    "* [Final Analysis](#step-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Imports and Definitions of Constants\n",
    "\n",
    "We will be using `pandas` to parse the data and `tensorflow` to construct the machine learning models. We will also be using the Yelp API to gather the data. In order to\n",
    "use the Yelp API, we need to create an API key to use in our API requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import scipy.stats as stats\n",
    "\n",
    "API_URL = \"https://api.yelp.com/v3/businesses\"\n",
    "SEARCH_URL = API_URL + \"/search\"\n",
    "RESTAURANT_IDS = \"rid.pkl\"\n",
    "\n",
    "with open(\"./API_KEY\", 'r') as f:\n",
    "    api_key = f.readline().strip()\n",
    "API_HEADERS = {\n",
    "    'Authorization': ' '.join(['Bearer', api_key])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step-1\"></a>\n",
    "\n",
    "## Part 1: Data Gathering from API\n",
    "\n",
    "In this step we will use the Yelp API to gather restaurant pages, then extract\n",
    "information using business search API requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Yelp API will only allow us to load business information from up to 1000\n",
    "distinct businesses on each search, we will first get the categories of the\n",
    "restaurants, then perform a search query for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurant_categories(url):\n",
    "    \"\"\"\n",
    "    This function gets all restaurant categories.\n",
    "    \n",
    "    @input url: URL to json file containing restaurant categories.\n",
    "    @type url: String.\n",
    "    \n",
    "    @return: List of restaurant categories.\n",
    "    @rtype: List of String\n",
    "    \"\"\"\n",
    "    cats = json.load(open(url))\n",
    "    return [cat['alias'] for cat in cats if 'restaurants' in cat['parents']]\n",
    "\n",
    "categories = get_restaurant_categories('categories.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the restaurant categories, we can write a function to find all\n",
    "restaurant IDs, and create a Pandas DataFrame. To aid debugging, we will dump\n",
    "the dataframe into a pickle file so that we will not have to regenerate each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UTNSUIY2QW6RYNa0xLa9gg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h5WkewI6U7NjLB_n6WgdvQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yOPbrFZ2ZUsyQWsedP6gUg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2ngodDyMj6M0szyBbGSJ5g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8ghGdEWOkGWUNeGrtdiaDQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id\n",
       "0  UTNSUIY2QW6RYNa0xLa9gg\n",
       "1  h5WkewI6U7NjLB_n6WgdvQ\n",
       "2  yOPbrFZ2ZUsyQWsedP6gUg\n",
       "3  2ngodDyMj6M0szyBbGSJ5g\n",
       "4  8ghGdEWOkGWUNeGrtdiaDQ"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_req_json(url, params=None):\n",
    "    \"\"\"\n",
    "    This function is a wrapper for a get request to the API.\n",
    "    \n",
    "    @input url: The API url.\n",
    "    @type url: String.\n",
    "    @input params: The parameters to pass to the get request.\n",
    "    @type params: Dict.\n",
    "    \n",
    "    @return: A json response.\n",
    "    @rtype: JSON\n",
    "    \"\"\"\n",
    "    response = requests.get(url=url, headers=API_HEADERS, params=params)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def find_restaurants(url, categories):\n",
    "    \"\"\"\n",
    "    This function loads all restaurant data from restaurants in NYC.\n",
    "    \n",
    "    @input url: The API url.\n",
    "    @type url: String.\n",
    "    @input categories: The restaurant categories.\n",
    "    @type categories: List of String.\n",
    "    \n",
    "    @return: A Pandas DataFrame containing the restaurant IDs.\n",
    "    @rtype: pandas.DataFrame.\n",
    "    \"\"\"\n",
    "    restaurants = []\n",
    "    for cat in categories:\n",
    "        params = {\n",
    "            'term': 'restaurants',\n",
    "            'location': 'NYC',\n",
    "            'categories': cat\n",
    "        }\n",
    "        content = get_req_json(url, params)\n",
    "        total = min(1000, content['total'])\n",
    "        i = 0\n",
    "        while i < total:\n",
    "            limit = min(50, total - i)\n",
    "            params['limit'] = limit\n",
    "            params['offset'] = i\n",
    "            content = get_req_json(url, params)\n",
    "            restaurants.extend([b['id'] for b in content['businesses']])\n",
    "            i += limit\n",
    "    return pd.DataFrame({'id': list(set(restaurants))})\n",
    "\n",
    "# Uncomment the following lines to get the restaurant IDs and recreate the pickle file.\n",
    "# restaurants = find_restaurants(SEARCH_URL, categories)\n",
    "# pickle.dump(restaurants, open(RESTAURANT_IDS, \"wb\"))\n",
    "\n",
    "# Load restaurant IDs from pickle file\n",
    "restaurant_ids = pickle.load(open(RESTAURANT_IDS, 'rb'))\n",
    "restaurant_ids.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step-2\"></a>\n",
    "\n",
    "## Part 2: Feature Extraction with Parsing\n",
    "\n",
    "Now that we have all the restaurant ids, in this step we can do a business lookup\n",
    "to get the specific data of the restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'UTNSUIY2QW6RYNa0xLa9gg',\n",
       " 'alias': 'new-pizza-professor-brooklyn-brooklyn',\n",
       " 'name': 'New Pizza Professor - Brooklyn',\n",
       " 'image_url': 'https://s3-media2.fl.yelpcdn.com/bphoto/zpkQadE2UF3DjvOBUHF9PA/o.jpg',\n",
       " 'is_claimed': True,\n",
       " 'is_closed': False,\n",
       " 'url': 'https://www.yelp.com/biz/new-pizza-professor-brooklyn-brooklyn?adjust_creative=ZAj1bx8bJHOcikvnMXVxEg&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_lookup&utm_source=ZAj1bx8bJHOcikvnMXVxEg',\n",
       " 'phone': '+13475874277',\n",
       " 'display_phone': '(347) 587-4277',\n",
       " 'review_count': 16,\n",
       " 'categories': [{'alias': 'pizza', 'title': 'Pizza'},\n",
       "  {'alias': 'kosher', 'title': 'Kosher'}],\n",
       " 'rating': 2.5,\n",
       " 'location': {'address1': '1824 Avenue M',\n",
       "  'address2': '',\n",
       "  'address3': None,\n",
       "  'city': 'Brooklyn',\n",
       "  'zip_code': '11230',\n",
       "  'country': 'US',\n",
       "  'state': 'NY',\n",
       "  'display_address': ['1824 Avenue M', 'Brooklyn, NY 11230'],\n",
       "  'cross_streets': '19th St & Bay Ave'},\n",
       " 'coordinates': {'latitude': 40.6184002, 'longitude': -73.9564177},\n",
       " 'photos': ['https://s3-media2.fl.yelpcdn.com/bphoto/zpkQadE2UF3DjvOBUHF9PA/o.jpg',\n",
       "  'https://s3-media4.fl.yelpcdn.com/bphoto/wTJKgZg2jvAbFjyxrKpfNg/o.jpg',\n",
       "  'https://s3-media2.fl.yelpcdn.com/bphoto/Mk5_1qxJEvgbhHoXlhsG9g/o.jpg'],\n",
       " 'hours': [{'open': [{'is_overnight': True,\n",
       "     'start': '1100',\n",
       "     'end': '0200',\n",
       "     'day': 0},\n",
       "    {'is_overnight': True, 'start': '1100', 'end': '0200', 'day': 1},\n",
       "    {'is_overnight': True, 'start': '1100', 'end': '0200', 'day': 2},\n",
       "    {'is_overnight': True, 'start': '1100', 'end': '0200', 'day': 3},\n",
       "    {'is_overnight': False, 'start': '1100', 'end': '1445', 'day': 4},\n",
       "    {'is_overnight': True, 'start': '2030', 'end': '0300', 'day': 5},\n",
       "    {'is_overnight': True, 'start': '1100', 'end': '0200', 'day': 6}],\n",
       "   'hours_type': 'REGULAR',\n",
       "   'is_open_now': False}],\n",
       " 'transactions': ['delivery', 'pickup']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data(rids, api_url):\n",
    "    \"\"\"\n",
    "    This function uses the Yelp business lookup API to get all data from each\n",
    "    restaurant.\n",
    "    \n",
    "    @input api_url: The API url.\n",
    "    @type api_url: String.\n",
    "    @input rids: The dataframe containing all restaurant IDs.\n",
    "    @type rids: pandas.DataFrame.\n",
    "    \n",
    "    @return: A list of restaurant information.\n",
    "    @rtype: List of Json Object.\n",
    "    \"\"\"\n",
    "    info = []\n",
    "    for idx, rid in rids.iterrows():\n",
    "        url = \"/\".join([api_url, rid['id']])\n",
    "        content = get_req_json(url)\n",
    "        info.append(content)\n",
    "    return info\n",
    "\n",
    "# Uncomment the following two lines to get the data from the API and save to pickle.\n",
    "# all_data = get_data(restaurant_ids, API_URL)\n",
    "# pickle.dump(all_data, open(\"restaurant_data.pkl\", \"wb\"))\n",
    "\n",
    "# Load all restaurant data from pickle file.\n",
    "all_data = pickle.load(open(\"restaurant_data.pkl\", 'rb'))\n",
    "all_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data that we obtained from the API, we can extract useful information from it to build\n",
    "a dataframe of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>delivery</th>\n",
       "      <th>fri_end</th>\n",
       "      <th>fri_is_overnight</th>\n",
       "      <th>fri_start</th>\n",
       "      <th>is_claimed</th>\n",
       "      <th>pickup</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>restaurant_reservation</th>\n",
       "      <th>sat_end</th>\n",
       "      <th>sat_is_overnight</th>\n",
       "      <th>sat_start</th>\n",
       "      <th>sun_end</th>\n",
       "      <th>sun_is_overnight</th>\n",
       "      <th>sun_start</th>\n",
       "      <th>wed_end</th>\n",
       "      <th>wed_is_overnight</th>\n",
       "      <th>wed_start</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kosher</td>\n",
       "      <td>1</td>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "      <td>1100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0300</td>\n",
       "      <td>1</td>\n",
       "      <td>2030</td>\n",
       "      <td>0200</td>\n",
       "      <td>1</td>\n",
       "      <td>1100</td>\n",
       "      <td>0200</td>\n",
       "      <td>1</td>\n",
       "      <td>1100</td>\n",
       "      <td>11230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comfortfood</td>\n",
       "      <td>1</td>\n",
       "      <td>0400</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0400</td>\n",
       "      <td>1</td>\n",
       "      <td>1100</td>\n",
       "      <td>2400</td>\n",
       "      <td>0</td>\n",
       "      <td>1100</td>\n",
       "      <td>0200</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>10016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>burgers</td>\n",
       "      <td>1</td>\n",
       "      <td>0300</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0300</td>\n",
       "      <td>1</td>\n",
       "      <td>1100</td>\n",
       "      <td>0200</td>\n",
       "      <td>1</td>\n",
       "      <td>1100</td>\n",
       "      <td>0200</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>10025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>greek</td>\n",
       "      <td>1</td>\n",
       "      <td>2200</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2200</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>2200</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>2200</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>11105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>creperies</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0800</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0900</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>0900</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>0800</td>\n",
       "      <td>11231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  delivery fri_end  fri_is_overnight fri_start  is_claimed  \\\n",
       "0       kosher         1    1445                 0      1100           1   \n",
       "1  comfortfood         1    0400                 1      1600           1   \n",
       "2      burgers         1    0300                 1      1200           1   \n",
       "3        greek         1    2200                 0      1200           0   \n",
       "4    creperies         1    2000                 0      0800           1   \n",
       "\n",
       "   pickup  price  rating  restaurant_reservation sat_end  sat_is_overnight  \\\n",
       "0       1      0     2.5                       0    0300                 1   \n",
       "1       1      2     4.0                       1    0400                 1   \n",
       "2       1      2     3.5                       0    0300                 1   \n",
       "3       1      1     3.0                       0    2200                 0   \n",
       "4       1      2     4.5                       0    2000                 0   \n",
       "\n",
       "  sat_start sun_end  sun_is_overnight sun_start wed_end  wed_is_overnight  \\\n",
       "0      2030    0200                 1      1100    0200                 1   \n",
       "1      1100    2400                 0      1100    0200                 1   \n",
       "2      1100    0200                 1      1100    0200                 1   \n",
       "3      1200    2200                 0      1200    2200                 0   \n",
       "4      0900    1800                 0      0900    1900                 0   \n",
       "\n",
       "  wed_start zip_code  \n",
       "0      1100    11230  \n",
       "1      1600    10016  \n",
       "2      1200    10025  \n",
       "3      1200    11105  \n",
       "4      0800    11231  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_features(data):\n",
    "    \"\"\"\n",
    "    This function creates a dataframe of features given a list of restaurant data.\n",
    "    \n",
    "    @input data: A list of restaurant data obtained from the Yelp API.\n",
    "    @type api_url: List of JSON Object.\n",
    "    \n",
    "    @return: A Pandas DataFrame containing the restaurant features.\n",
    "    @rtype: pandas.DataFrame.\n",
    "    \"\"\"\n",
    "    prices, ratings, pickups, deliveries= [], [], [], []\n",
    "    reservations, is_claimed, zipcodes, categories = [], [], [], []\n",
    "    days = [2, 4, 5, 6]\n",
    "    hours = dict()\n",
    "    for day in days:\n",
    "        hours[day] = []\n",
    "    for content in (x for x in data if 'error' not in x):\n",
    "        prices.append(len(content.get('price', \"\")))\n",
    "        ratings.append(float(content.get('rating', 0)))\n",
    "        transactions = content.get('transactions', [])\n",
    "        pickups.append(int(\"pickup\" in transactions))\n",
    "        deliveries.append(int(\"delivery\" in transactions))\n",
    "        reservations.append(int(\"restaurant_reservation\" in transactions))\n",
    "        is_claimed.append(int(content.get('is_claimed', False)))\n",
    "        if ('location' not in content) or ('zip_code' not in content['location']):\n",
    "            zipcodes.append('0')\n",
    "        else:\n",
    "            zipcodes.append(content['location']['zip_code'])\n",
    "        for day in days:\n",
    "            if \"hours\" in content:\n",
    "                open_hours = content[\"hours\"][0][\"open\"]\n",
    "                stats = [h for h in open_hours if h['day'] == day]\n",
    "                is_overnight = int(True in [h['is_overnight'] for h in stats])\n",
    "                start = min([h['start'] for h in stats], default='0000')\n",
    "                end = max([h['end'] if h['end'] != '0000' else '2400' for h in stats], default='0000')\n",
    "                hours[day].append([is_overnight, start, end])\n",
    "            else:\n",
    "                hours[day].append([0, '1200', '1800'])\n",
    "        cat_list = [c['alias'] for c in content['categories']]\n",
    "        categories.append(np.random.choice(cat_list, 1)[0])\n",
    "        \n",
    "    for day in days:\n",
    "        hours[day] = np.array(hours[day])\n",
    "    df_dict = {\n",
    "        'price': prices,\n",
    "        'category': categories,\n",
    "        'pickup': pickups,\n",
    "        'delivery': deliveries,\n",
    "        'restaurant_reservation': reservations,\n",
    "        'is_claimed': is_claimed,\n",
    "        'zip_code': zipcodes,\n",
    "        'rating': ratings,\n",
    "        'wed_is_overnight': hours[2][:, 0].astype(int),\n",
    "        'fri_is_overnight': hours[4][:, 0].astype(int),\n",
    "        'sat_is_overnight': hours[5][:, 0].astype(int),\n",
    "        'sun_is_overnight': hours[6][:, 0].astype(int),\n",
    "        'wed_start': hours[2][:, 1],\n",
    "        'fri_start': hours[4][:, 1],\n",
    "        'sat_start': hours[5][:, 1],\n",
    "        'sun_start': hours[6][:, 1],\n",
    "        'wed_end': hours[2][:, 2],\n",
    "        'fri_end': hours[4][:, 2],\n",
    "        'sat_end': hours[5][:, 2],\n",
    "        'sun_end': hours[6][:, 2]\n",
    "    }\n",
    "    return pd.DataFrame(df_dict)\n",
    "\n",
    "# Extract features from the loaded restaurant data\n",
    "labeled_features = extract_features(all_data)\n",
    "labeled_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"step-3\"></a>\n",
    "\n",
    "## Part 3: Feature Analysis and Variable Selection\n",
    "\n",
    "Now that we have the features, we can separately analyse them and see how each feature\n",
    "contributes to the rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Price\n",
    "There are four levels (1, 2, 3, or 4) in price. Let's plot the frequency distribution of ratings for each price level to see if they differ alot, and then run an one-way ANOVA test to see if the population means of the ratings are different for at least two price levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [12,8]\n",
    "\n",
    "def barplot_each_price(price_levels, rating, df):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    - price_levels is the list of possible price levels\n",
    "    - rating is the list of possible ratings\n",
    "    - df is the pandas dataframe containing the data\n",
    "    \n",
    "    This function plots the bar chart of the ratings for each of the price levels\n",
    "    \"\"\"\n",
    "    for i in price_levels:\n",
    "        price = i\n",
    "        # ratings with this price level\n",
    "        this_price_df = df.loc[df['price']==price]\n",
    "        data = this_price_df['rating']\n",
    "        counter = Counter(data)\n",
    "        freq = [counter[rate] for rate in rating]\n",
    "        plt.subplot(2,2,i)\n",
    "        plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "        plt.bar(rating, freq, width=0.2)\n",
    "        plt.xlabel(\"Rating\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.ylim(ymin=0, ymax=3000)\n",
    "        plt.xticks(rating, rating)\n",
    "        plt.title(\"Price Level: %s\"%price)\n",
    "\n",
    "barplot_each_price(price_levels=[1,2,3,4], rating=np.linspace(1, 5, 9), df=labeled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've set the y-axis range to be the same for all four subplots so that visually comparing becomes easier. The shapes of the rating frequencies appear very different. But such a visual impression might be due to the number of restaurants being so different for each price level rather than the distributions being different. So let's perform ANOVA to yield some formal conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=48.77633760216919, pvalue=2.367994922849704e-31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def price_oneway_ANOVA(price_levels, df):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    - price_levels is the list of possible price levels\n",
    "    - df is the pandas dataframe containing the data\n",
    "    \n",
    "    This function returns the output of one-way ANOVA on ratings across different price levels\n",
    "    \"\"\"\n",
    "    # This dictionary will have each key being each price level, and the corresponding value will be the array\n",
    "    # of the ratings of the restaurants with that price level\n",
    "    price_rating_dict = dict()\n",
    "    for price in price_levels:\n",
    "        this_price_df = df.loc[df['price']==price]\n",
    "        price_rating_dict[price] = np.array(this_price_df['rating'])\n",
    "    return stats.f_oneway(*price_rating_dict.values())\n",
    "\n",
    "price_oneway_ANOVA(price_levels=[1,2,3,4], df=labeled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the ANOVA output, at $\\alpha=0.01$, the p-value is less than $\\alpha$, so we conclude at least two price levels have population rating means that are different. A limitation of one-way ANOVA is that we can't conclude which groups have different population rating means, but in our context, knowing that the rating means differ in at least two levels lets us conclude price is an important feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Transactions (Pickup, Delivery, Reservation)\n",
    "\n",
    "We've parsed the transaction features as: \"pickup\" is 1 if pickup is available in that restaurant and 0 otherwise, and similarly for \"delivery\" and \"restaurant_reservation\". For each of the three transaction features, let's use two-sample t-test (one group of the restaurants that have that transaction, and the other group of those that don't) to determine if the two groups have differnt population rating means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup : Ttest_indResult(statistic=3.448779997551905, pvalue=0.0005645728857015097)\n",
      "delivery : Ttest_indResult(statistic=5.562932502127382, pvalue=2.6951061936021385e-08)\n",
      "restaurant_reservation : Ttest_indResult(statistic=-14.809667384237882, pvalue=1.2817988406449425e-47)\n"
     ]
    }
   ],
   "source": [
    "def two_sample_ttest(feature_name, values, df):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    - feature_name is the name of the feature\n",
    "    - values is the list of 2 possible values (which determine the 2 groups)\n",
    "    - df is the pandas dataframe containing the data\n",
    "    \n",
    "    This function returns the output of one-way ANOVA on ratings across different price levels\n",
    "    \"\"\"\n",
    "    feature_rating_dict = dict()\n",
    "    for value in values:\n",
    "        this_value_df = df.loc[df[feature_name]==value]\n",
    "        feature_rating_dict[value] = np.array(this_value_df['rating'])\n",
    "    return stats.ttest_ind(*feature_rating_dict.values(), equal_var=False)\n",
    "\n",
    "transaction_vars = ['pickup', 'delivery', 'restaurant_reservation']\n",
    "for feature in transaction_vars:\n",
    "    print(feature, \":\", two_sample_ttest(feature_name=feature, values=[0,1], df=labeled_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the t-test output, for each of the three transaction features, at $\\alpha=0.01$, the p-value is less than $\\alpha$, so we conclude the two groups have population rating means that are different. One might think that all three features should be included in the model.\n",
    "\n",
    "But common sense makes us suspicious about correlations among the transaction features, and in general, correlated features can cause problems in modeling (e.g. multicollinearity problem in linear regression). Let's examine the correlation coefficient for each pair among the three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup , delivery 0.9303345646034946\n",
      "pickup , restaurant_reservation 0.11267822332819287\n",
      "delivery , restaurant_reservation 0.09576221912941747\n"
     ]
    }
   ],
   "source": [
    "def print_pcc(list_vars, df):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    - list_vars is the list of feature names in which the Pearson Correlation Coefficient for each pair is computed\n",
    "    - df is the pandas dataframe containing the data\n",
    "    \n",
    "    This function prints the Pearson Correlation Coefficient for each pair of the features provided in the list\n",
    "    \"\"\"\n",
    "    for i in range(0, len(list_vars)):\n",
    "        for j in range(i+1, len(list_vars)):\n",
    "            corr = np.corrcoef(df[list_vars[i]], df[list_vars[j]])[0,1]\n",
    "            print(list_vars[i],  \",\", list_vars[j], corr)\n",
    "\n",
    "print_pcc(transaction_vars, df=labeled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickup and delivery are highly correlated, but the other two pairs are fine. So among the three, we decide to include reservation and only one of pickup and delivery. Between the two correlated features, we choose delivery since its t-test p-value is lower than pickup's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Zip Code\n",
    "\n",
    "Let's plot a bubble plot of the ratings and zip codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [16,10]\n",
    "\n",
    "def bubbleplot_two_vars(var1, var2, df):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    - var1 is the name of the first variable (which is a column in the dataframe)\n",
    "    - var1 is the name of the second variable (which is a column in the dataframe)\n",
    "    - df is the dataframe containing the data\n",
    "    \n",
    "    This function plots a bubble plot of the two variables in the dataframe\n",
    "    \"\"\"\n",
    "    pairs = np.array(df[[var1, var2]]).astype(str)\n",
    "    label_x, x = np.unique(pairs[:,0], return_inverse=True)\n",
    "    label_y, y = np.unique(pairs[:,1], return_inverse=True)\n",
    "    xy, cnts = np.unique((x,y), axis=1, return_counts=True)\n",
    "    plt.scatter(xy[0], xy[1], s=cnts*8)\n",
    "    plt.xlabel(\"Zip Code\")\n",
    "    plt.ylabel(\"Rating\")\n",
    "    plt.title(\"Rating vs Zip Code; Point size indicates count\")\n",
    "    plt.xticks(range(len(label_x)), label_x)\n",
    "    plt.yticks(range(len(label_y)), label_y)\n",
    "\n",
    "bubbleplot_two_vars(var1='zip_code', var2='rating', df=labeled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in some zip codes, the ratings of 4.0 and 3.5 are clearly dominant, while for other zip codes, all the ratings are similarly frequent. This plot suggests that ratings do differ for different zip codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's perform one-way ANOVA on the zip codes to check if at least two zip codes have different population mean of ratings. Few rows in our dataframe have missing zip code information and have them recorded as either \"0\", \"\", or None. So we exclude them when performing ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=4.428869810981315, pvalue=3.9649519708657156e-88)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def zipcode_oneway_ANOVA(zipcodes, df):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    - zipcodes is the list of zip codes\n",
    "    - df is the pandas dataframe containing the data\n",
    "    \n",
    "    This function returns the output of one-way ANOVA on ratings across different zip codes\n",
    "    \"\"\"\n",
    "    # This dictionary will have each key being each zip code, and the corresponding value will be the array\n",
    "    # of the ratings of the restaurants with that zip code\n",
    "    zipcode_rating_dict = dict()\n",
    "    for zipcode in zipcodes:\n",
    "        this_zipcode_df = df.loc[df['zip_code']==zipcode]\n",
    "        zipcode_rating_dict[zipcode] = np.array(this_zipcode_df['rating'])\n",
    "    return stats.f_oneway(*zipcode_rating_dict.values())\n",
    "\n",
    "unique_zipcodes = labeled_features['zip_code'].unique()\n",
    "unique_zipcodes = unique_zipcodes[unique_zipcodes != \"0\"]\n",
    "unique_zipcodes = unique_zipcodes[unique_zipcodes != \"\"]\n",
    "unique_zipcodes = unique_zipcodes[unique_zipcodes != None]\n",
    "zipcode_oneway_ANOVA(zipcodes=unique_zipcodes, df=labeled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the ANOVA output, at $\\alpha=0.01$, the p-value is less than $\\alpha$, so we conclude at least two zip codes have population rating means of restaurants that are different, and so we consider zip code an important feature. \n",
    "\n",
    "**NOTE**: Since we'll include it in our modeling, we should remove the few rows with invalid zip codes (\"0\", \"\", or None) from our dataframe before setting up models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Claimed\n",
    "\n",
    "A claimed business page in Yelp is one that has been claimed by the owner or representative of the business through our verification process. Let's plot the frequency of ratings for the claimed restaurants and that for nonclaimed restaurants, and then perform two-sample t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10,4]\n",
    "\n",
    "def barplot_claimed(rating, df):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    - rating is the list of possible ratings\n",
    "    - df is the pandas dataframe containing the data\n",
    "    \n",
    "    This function overplots the bar chart of the ratings for restaurants claimed and those that are not.\n",
    "    \"\"\"\n",
    "    for i in [0,1]:\n",
    "        subplot_index = i + 1\n",
    "        # ratings of claimed restaurants\n",
    "        this_price_df = df.loc[df['is_claimed']==i]\n",
    "        data = this_price_df['rating']\n",
    "        counter = Counter(data)\n",
    "        freq = [counter[rate] for rate in rating]\n",
    "        plt.subplot(1,2,subplot_index)\n",
    "        plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "        plt.bar(rating, freq, width=0.2)\n",
    "        plt.xlabel(\"Rating\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.ylim(ymin=0, ymax=4000)\n",
    "        plt.xticks(rating, rating)\n",
    "        plt.title(\"Claimed\" if i==1 else \"Not Claimed\")\n",
    "\n",
    "barplot_claimed(rating=np.linspace(1, 5, 9), df=labeled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar charts suggest that the frequencies are considerably different, especially in terms of how dominantly frequent ratings of 3.5 or 4 are. Let's perform two-sample t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-19.620624050804704, pvalue=2.4638528098179564e-83)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sample_ttest(feature_name='is_claimed', values=[0,1], df=labeled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the t-test output, at $\\alpha=0.01$, the p-value is less than $\\alpha$, so we conclude the two groups have population rating means that are different and thus treat whether or not the restaurant is claimed as a meaningful feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step-4\"></a>\n",
    "\n",
    "## Part 4: Setup of Models\n",
    "\n",
    "We need to construct a couple machine learning models for us to train to see which\n",
    "one gives us the best testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(object):\n",
    "    \"\"\"\n",
    "    This is a neural network.\n",
    "    \"\"\"\n",
    "    def __init__(self, layers=[5, 5]):\n",
    "        self.layers = layers\n",
    "        \n",
    "class LogisticRegression(object):\n",
    "    \"\"\"\n",
    "    This is the logistic regression model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.theta = np.zeros(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step-5\"></a>\n",
    "\n",
    "## Part 5: Cross Validation\n",
    "\n",
    "Now we will use cross-validation to determine which model produces the highest\n",
    "validation accuracy for our dataset, then pick this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_model():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step-6\"></a>\n",
    "\n",
    "## Part 6: Final Analysis\n",
    "\n",
    "Our results were amazing, so yeah."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
